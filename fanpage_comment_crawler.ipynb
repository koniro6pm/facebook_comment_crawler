{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from queue import Queue\n",
    "import multiprocessing\n",
    "import threading\n",
    "import os, re, time\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "import configparser\n",
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import json\n",
    "import signal\n",
    "import stopit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @stopit.threading_timeoutable('unexpected')\n",
    "# def infinite():\n",
    "#     while True:\n",
    "#         pass\n",
    "#     return 'whatever'\n",
    "# infinite(timeout=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### init and read config\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "MONGO_DB = config[\"Database\"][\"MONGO_DB\"]\n",
    "MONGO_HOST=config[\"Database\"][\"HOST\"]\n",
    "MONGO_USER = config[\"Database\"][\"MONGO_USER\"]\n",
    "MONGO_PASS = config[\"Database\"][\"MONGO_PASS\"]\n",
    "\n",
    "mongoURI = \"mongodb://%s:%s@%s/%s?authMechanism=SCRAM-SHA-1\" % (MONGO_USER, MONGO_PASS, MONGO_HOST, MONGO_DB)\n",
    "conn = MongoClient(mongoURI)\n",
    "db = conn[MONGO_DB]\n",
    "handler = db['fanpage_post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTime(stime):\n",
    "    \n",
    "    try:\n",
    "        tmp = stime.split(\" \")[1].split(\"|\")[0]\n",
    "        hour = re.sub(\"[^0-9]\",\"\",tmp.split(\":\")[0])\n",
    "        minute = tmp.split(\":\")[1]\n",
    "        if tmp[3:5] == \"下午\":\n",
    "            hour = str(int(hour) + 12)\n",
    "            if hour == \"24\":\n",
    "                hour = \"00\"\n",
    "        sdatetime = stime.split(\" \")[0]+\" \"+hour+\":\"+minute\n",
    "        postTime =  datetime.datetime.strptime(sdatetime, '%Y年%m月%d日 %H:%M')\n",
    "    except:\n",
    "        postTime = \"\"\n",
    "        \n",
    "    return postTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commentParser(soup):\n",
    "    \n",
    "    commentList = []\n",
    "    commenttable = soup.select(\".commentable_item ul\")[0].find_all(\"li\",recursive=False) #recursive=False只找直接子結點\n",
    "\n",
    "    for comment in commenttable:\n",
    "        main = comment.find(\"div\",{\"aria-label\":\"留言\"})\n",
    "        name = main.find(\"img\")['alt']\n",
    "        try:\n",
    "            content = main.find(\"span\",{\"dir\":\"ltr\"}).get_text(strip=True)\n",
    "        except:\n",
    "            content = \"\" #只貼圖片，沒有文字內容\n",
    "        try:\n",
    "            stime = main.find(\"abbr\")['data-tooltip-content']\n",
    "        except:\n",
    "            stime = main.find(\"abbr\")['title']\n",
    "        postTime = convertTime(stime)\n",
    "\n",
    "        mainDic = {\n",
    "            \"name\":name,\n",
    "            \"content\":content,\n",
    "            \"postTime\":postTime,\n",
    "            #\"stime\":stime\n",
    "        }\n",
    "        subCommentList = []\n",
    "        subComment = comment.find_all(\"div\",{\"aria-label\":\"留言回覆\"})\n",
    "        if subComment != None: #有子留言\n",
    "            for sub in subComment:\n",
    "                name = sub.find(\"img\")['alt']\n",
    "                try:\n",
    "                    content = sub.find(\"span\",{\"dir\":\"ltr\"}).get_text(strip=True)\n",
    "                except:\n",
    "                    content = \"\" #只貼圖片，沒有文字內容\n",
    "                try:\n",
    "                    stime = main.find(\"abbr\")['data-tooltip-content']\n",
    "                except:\n",
    "                    stime = main.find(\"abbr\")['title']\n",
    "                postTime = convertTime(stime)\n",
    "\n",
    "                subDic = {\n",
    "                    \"name\":name,\n",
    "                    \"content\":content,\n",
    "                    \"postTime\":postTime,\n",
    "                    #\"stime\":stime\n",
    "                }\n",
    "                subCommentList.append(subDic)\n",
    "\n",
    "        mainDic[\"subComment\"] = subCommentList\n",
    "        commentList.append(mainDic)\n",
    "    return commentList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@stopit.threading_timeoutable(\"timeout\")\n",
    "def crawler(url):\n",
    "    \n",
    "    try:\n",
    "        opts = Options()\n",
    "        #opts.set_headless(headless=True)\n",
    "        driver = webdriver.Firefox(options=opts)\n",
    "        driver.get(url)\n",
    "        time.sleep(5) # 等待稍後再說出現\n",
    "        \n",
    "        raw = \"\"\n",
    "        comment = []\n",
    "        error = False\n",
    "        \n",
    "        #點擊稍後在說        \n",
    "        try:\n",
    "            driver.find_element_by_link_text(\"稍後再說\").click()\n",
    "        except: #不用點稍後再說\n",
    "            pass\n",
    "        \n",
    "        html_doc=driver.page_source\n",
    "        soup = BeautifulSoup(html_doc, 'lxml')\n",
    "\n",
    "\n",
    "        ## ver1\n",
    "        #有可能右側欄出現同樣留言數的\n",
    "        \n",
    "        try:\n",
    "            expand = soup.find(\"div\", {\"class\": \"userContentWrapper\"}).find(\"form\", {\"class\": \"commentable_item\"}).find(\"a\", string=re.compile(\"^\\s*[0-9]*\\s*則留言\"))\n",
    "            num = len(soup.find_all(\"a\",text = expand.text)) # X則留言\n",
    "            element = driver.find_element_by_link_text(expand.text)\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", element) #滾輪滑倒X則留言位置\n",
    "            driver.find_element_by_xpath(\"(//a[text()='\"+expand.text+\"'])[last()]\").click()\n",
    "\n",
    "            #driver.find_element_by_link_text(expand.text).click() #點擊X則留言\n",
    "            \n",
    "            ### test \n",
    "            \n",
    "            #print(driver.find_element_by_xpath(\"//form[@class='commentable_item']\").text)\n",
    "            \n",
    "            #print(\"//form[@class='commentable_item']//a[text()='\"+expand.text+\"']\")\n",
    "            #driver.find_element_by_xpath(\"//form[@class='commentable_item']//a[text()='\"+expand.text+\"']\").click()\n",
    "            #print(\"click\",expand.text)\n",
    "            #//*[@id=\"u_0_u\"]/div/div[2]/div[1]/div/div[3]/span[1]/a\n",
    "        except:\n",
    "            error = \"NotFindContent\" #需要的登入的頁面 會找不到userContentWrapper\n",
    "\n",
    "\n",
    "        ## ver2\n",
    "        #找到展開留言element\n",
    "        #expand = soup.find(\"div\", {\"class\": \"userContentWrapper\"}).find(\"form\", {\"class\": \"commentable_item\"}).find(\"a\", string=re.compile(\"^\\s*[0-9]*\\s*則留言\"))\n",
    "        #一定要滑倒這個userContentWrapper裡X則留言的element，不然右側欄可能會有一樣X則留言\n",
    "        #driver.find_element_by_css_selector(\".commentable_item span[data-hover='tooltip'] a\").click()\n",
    "        #driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "        #driver.find_element_by_link_text(expand.text).click()\n",
    "        #element = driver.find_element_by_css_selector(\"div[class='userContentWrapper'] form[class='commentable_item']\")\n",
    "        #element = driver.find_element_by_xpath(\"//form[@class='commentable_item']/\")\n",
    "\n",
    "        # element = driver.find_element_by_link_text(expand)\n",
    "        # driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "        #點擊展開留言element\n",
    "\n",
    "        #driver.find_element_by_css_selector(\"div[class='userContentWrapper'] form[class='commentable_ite'] a[data-ft='{'tn':'O'}']\").click() #點擊\"X則留言\"  有可能發生右邊側欄其他貼文 留言數量一樣\n",
    "        time.sleep(3)\n",
    "\n",
    "#         try:\n",
    "#             element = driver.find_element_by_link_text(\"最相關\")\n",
    "#             driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "#             driver.find_element_by_link_text(\"最相關\").click()\n",
    "#             #print(\"click 最相關\")\n",
    "#             time.sleep(2)\n",
    "#             html_doc=driver.page_source\n",
    "#             soup = BeautifulSoup(html_doc, 'lxml')\n",
    "#             driver.find_element_by_xpath(\"//ul[@role='menu']/li[3]\").click() \n",
    "#         except:\n",
    "#             #沒有「最相關」，而是在右邊顯示「最早」\n",
    "#             pass\n",
    "#         time.sleep(3)\n",
    "#         html_doc=driver.page_source\n",
    "#         soup = BeautifulSoup(html_doc, 'lxml')\n",
    "\n",
    "\n",
    "        #展開所有留言，直到沒有\n",
    "        while True:\n",
    "            html_doc=driver.page_source\n",
    "            soup = BeautifulSoup(html_doc, 'lxml')\n",
    "\n",
    "            #展開留言有兩種text\n",
    "            expand1 = soup.find(\"span\", string=re.compile(\"^檢視另\\s*[0-9]*\\s*則留言\"))\n",
    "            expand2 = soup.find(\"span\", string=re.compile(\"查看更多留言\"))\n",
    "            expand3 = soup.find(\"span\", string=re.compile(\"^查看另\\s*[0-9]*\\s*則留言\"))\n",
    "\n",
    "            if expand1 != None: #沒有檢視另x則留言了，        \n",
    "                element = driver.find_element_by_link_text(expand1.text)\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "                driver.find_element_by_link_text(expand1.text).click()\n",
    "                #print(\"展開留言\")\n",
    "                time.sleep(5)        \n",
    "            elif expand2 != None:\n",
    "                element = driver.find_element_by_link_text(expand2.text)\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "                driver.find_element_by_link_text(expand2.text).click()\n",
    "                #print(\"展開留言\")\n",
    "                time.sleep(5)\n",
    "            elif expand3 != None:\n",
    "                element = driver.find_element_by_link_text(expand3.text)\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "                driver.find_element_by_link_text(expand3.text).click()\n",
    "                #print(\"展開留言\")\n",
    "                time.sleep(5)\n",
    "            else: #兩種都沒找到，沒有留言了\n",
    "                #print(\"展開所有留言\")\n",
    "                break\n",
    "\n",
    "        #print(\"展開所有留言\")\n",
    "        time.sleep(3)\n",
    "\n",
    "        #driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") #利用js滑到頁面最下方\n",
    "\n",
    "        #展開所有子留言，直到沒有\n",
    "\n",
    "        while True:\n",
    "            html_doc=driver.page_source\n",
    "            soup = BeautifulSoup(html_doc, 'lxml')\n",
    "            expand1 = soup.find_all(\"span\", string=re.compile(\"^檢視另\\s*[0-9]*\\s*則回覆\"))\n",
    "            expand2 = soup.find_all(\"span\", string=re.compile(\"^\\s*[0-9]*\\s*則回覆\"))\n",
    "            expand3 = soup.find_all(\"a\", string=re.compile(\"^查看更多\"))\n",
    "\n",
    "            if len(expand1) > 0: #沒有檢視另x則回覆了，跳出\n",
    "                for button in expand1:\n",
    "                    element = driver.find_element_by_link_text(button.text)\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "                    driver.find_element_by_link_text(button.text).click()\n",
    "                    time.sleep(2)\n",
    "                    #print(\"click\",button.text)\n",
    "\n",
    "            if len(expand2) > 0: #沒有檢視另x則回覆了，跳出\n",
    "                for button in expand2:\n",
    "                    element = driver.find_element_by_link_text(button.text)\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "                    driver.find_element_by_link_text(button.text).click()\n",
    "                    time.sleep(2)\n",
    "                    #print(\"click\",button.text)\n",
    "\n",
    "            if len(expand3) > 0: #沒有檢視另x則回覆了，跳出\n",
    "                for button in expand3:\n",
    "                    element = driver.find_element_by_link_text(button.text)\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "                    driver.find_element_by_link_text(button.text).click()\n",
    "                    time.sleep(2)\n",
    "                    #print(\"click\",button.text)\n",
    "\n",
    "            if len(expand1) == 0 and len(expand2) == 0 and len(expand3) == 0:\n",
    "                #print(\"展開所有子留言\")\n",
    "                break\n",
    "\n",
    "\n",
    "        #最終全部展開留言的html\n",
    "        html_doc=driver.page_source\n",
    "        soup = BeautifulSoup(html_doc, 'lxml')\n",
    "        comment = commentParser(soup)\n",
    "        error = False\n",
    "        try:\n",
    "            raw = soup.find(\"form\", {\"class\": \"commentable_item\"})\n",
    "        except: # 沒點擊到本文的展開留言\n",
    "            error = \"NotFindTable\"\n",
    "            raw = \"\"\n",
    "            comment = []\n",
    "\n",
    "    except WebDriverException:\n",
    "        print(\"url error\",url)\n",
    "        error = \"WebDriverException\"\n",
    "\n",
    "    except stopit.utils.TimeoutException:\n",
    "        print(\"timeout exception\")\n",
    "\n",
    "        error = \"TimeoutExceptino\"\n",
    "        \n",
    "    except:\n",
    "        error = \"Other\"\n",
    "        \n",
    "    dic = {\n",
    "        \"url\":url,\n",
    "        \"comment_raw\":str(raw),\n",
    "        \"comment\":comment,\n",
    "        \"error\":error\n",
    "    }\n",
    "\n",
    "    driver.close()\n",
    "    \n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thread_crawl(url,wait,q):\n",
    "    result = crawler(url,timeout=wait)\n",
    "    q.put(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "max_bag = 5 #一次幾個子線程\n",
    "count = 0\n",
    "wait = 0 #主線程等待時間\n",
    "tmp = []\n",
    "\n",
    "#sort([(\"review_num\", pymongo.ASCENDING)]) : 根據review_num做sort，review_num相近的頁面一起爬，這樣多線程比較省時間\n",
    "#前制作業要先在資料庫建立review_num的ASCENDING index，否則會顯示RAM不夠\n",
    "# with handler.find({'review_num':{'$gt':0},'comment_raw':{'$exists':False},'error':{'$exists':False}},{'url':1,'review_num':1},no_cursor_timeout=True).sort([(\"review_num\", pymongo.ASCENDING)]) as cursor:\n",
    "with handler.find({'review_num':{'$gt':0},'comment_raw':\"\"},{'url':1,'review_num':1},no_cursor_timeout=True).sort([(\"review_num\", pymongo.ASCENDING)]) as cursor:\n",
    "\n",
    "    for row in cursor:\n",
    "            \n",
    "        if count == 0:\n",
    "            start_time  = datetime.datetime.now()\n",
    "            q = Queue()\n",
    "            threads = []      \n",
    "        #url = row['result link']\n",
    "        wait = row['review_num']*30\n",
    "        print(\"wait\",wait)\n",
    "        t = threading.Thread(target=thread_crawl, args=[row['url'],wait,q])\n",
    "        #t.daemon = True\n",
    "        threads.append(t)\n",
    "        \n",
    "        #wait = wait + row['review_num'] #根據review_num來決定總等待時間\n",
    "        wait = []\n",
    "        wait.append(row['review_num'])\n",
    "        count = count + 1\n",
    "        t.start()\n",
    "\n",
    "        if count == max_bag: #每200筆清空一次thread\n",
    "            for t in threads:\n",
    "                t.join()\n",
    "            #print(list(q.queue))\n",
    "            for p in list(q.queue):\n",
    "                handler.update_one(\n",
    "                {'url':p['url']},\n",
    "                {'$set':p}\n",
    "                )\n",
    "                \n",
    "            total = total+max_bag\n",
    "            time_elapsed = datetime.datetime.now() - start_time\n",
    "            print(total,'Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))\n",
    "            count = 0\n",
    "            wait = 0\n",
    "\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    if len(list(q.queue)) > 0:\n",
    "        #print(list(q.queue)[0])\n",
    "        for p in list(q.queue):\n",
    "            handler.update_one(\n",
    "            {'url':p['url']},\n",
    "            {'$set':p}\n",
    "            )\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total = 0\n",
    "# max_bag = 5 #一次幾個子線程\n",
    "# count = 0\n",
    "# wait = 0 #主線程等待時間\n",
    "# tmp = []\n",
    "\n",
    "# #sort([(\"review_num\", pymongo.ASCENDING)]) : 根據review_num做sort，review_num相近的頁面一起爬，這樣多線程比較省時間\n",
    "# #前制作業要先在資料庫建立review_num的ASCENDING index，否則會顯示RAM不夠\n",
    "# #with handler.find({'review_num':{'$gt':0},'comment_raw':{'$exists':False},'error':{'$exists':False}},{'url':1,'review_num':1},no_cursor_timeout=True).sort([(\"review_num\", pymongo.ASCENDING)]) as cursor:\n",
    "# with handler.find({'review_num':{'$gt':0},'comment_raw':\"\"},{'url':1,'review_num':1},no_cursor_timeout=True).sort([(\"review_num\", pymongo.ASCENDING)]) as cursor:\n",
    "\n",
    "#     for row in cursor:\n",
    "        \n",
    "#         wait = row['review_num']*30\n",
    "#         #print(\"wait\",wait)\n",
    "#         result = crawler(row['url'],wait)\n",
    "#         handler.update_one(\n",
    "#         {'url':result['url']},\n",
    "#         {'$set':result}\n",
    "#         )\n",
    "#         count +=1\n",
    "#         print(count)\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test zone"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:36]",
   "language": "python",
   "name": "conda-env-36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
